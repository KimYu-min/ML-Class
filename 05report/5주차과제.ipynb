{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 1.000\n",
      "테스트 세트 정확도 : 0.965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# learning_rate는 기본이 0.1\n",
    "# n_estimators = 100, max_depth = 3 : 깊이가 3인 트리 100개\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                   random_state=0)\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 과대적합이 나타난다는 것을 알 수 있다.\n",
    "#### - 트리 최대 깊이를 줄여서 사전 가지치기를 수행하거나 학습률(learning_rate)을 낮춰서 과대적합을 피할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 정확도 CV = 10 : 0.890\n",
      "테스트 세트 정확도 CV = 5 : 0.850\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "cvscores = cross_val_score(gbrt, X, y, cv=10)\n",
    "print(\"테스트 세트 정확도 CV = 10 : {:.3f}\".format(cvscores.mean()))\n",
    "\n",
    "cvscores = cross_val_score(gbrt, X, y, cv=5)\n",
    "print(\"테스트 세트 정확도 CV = 5 : {:.3f}\".format(cvscores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - cross_val_score 함수를 통해 교차검증을 수행한다.\n",
    "#### - cv를 크게 하여 교차검증을 할수록 테스트 세트 정확도가 향상된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.973\n",
      "테스트 세트 정확도 : 0.840\n",
      "\n",
      "테스트 세트 정확도 CV = 10 : 0.890\n",
      "테스트 세트 정확도 CV = 5 : 0.870\n"
     ]
    }
   ],
   "source": [
    "# max_depth = 1 : 과적합 피하고 테스트 데이터 성능 향상\n",
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\\n\".format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "cvscores = cross_val_score(gbrt, X, y, cv=10)\n",
    "print(\"테스트 세트 정확도 CV = 10 : {:.3f}\".format(cvscores.mean()))\n",
    "\n",
    "cvscores = cross_val_score(gbrt, X, y, cv=5)\n",
    "print(\"테스트 세트 정확도 CV = 5 : {:.3f}\".format(cvscores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 트리 최대 깊이(max_depth)를 작게 했더니 테스트 세트 정확도가 향상했다.\n",
    "#### - 과대적합이 해소된 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.907\n",
      "테스트 세트 정확도 : 0.880\n",
      "\n",
      "테스트 세트 정확도 CV = 10 : 0.870\n",
      "테스트 세트 정확도 CV = 5 : 0.860\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.01 : 테스트 데이터 정확도 조금 감소\n",
    "gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\\n\".format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "cvscores = cross_val_score(gbrt, X, y, cv=10)\n",
    "print(\"테스트 세트 정확도 CV = 10 : {:.3f}\".format(cvscores.mean()))\n",
    "\n",
    "cvscores = cross_val_score(gbrt, X, y, cv=5)\n",
    "print(\"테스트 세트 정확도 CV = 5 : {:.3f}\".format(cvscores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 학습률(learning_rate)을 줄이자 이전 트리의 오차 보정을 약하게 하여 테스트 정확도가 조금 떨어진 것을 알 수 있다.\n",
    "#### - 과대적합이 해소됐으나 정확도를 위해 적절한 수를 찾아서 조정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.90\n",
      "테스트 세트 정확도 : 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# 유방암 데이터\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                   random_state=0)\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.2f}\".format(svc.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.2f}\".format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.984\n",
      "테스트 세트 정확도 : 0.909\n"
     ]
    }
   ],
   "source": [
    "# 성능 향상을 위한 데이터 전처리\n",
    "\n",
    "# 훈련 세트 특성 별 최솟값 계산\n",
    "min_on_training = X_train.min(axis=0)\n",
    "# 훈련 세트 특성 별 (최댓값 - 최솟값) 범위 계산\n",
    "range_on_training = (X_train - min_on_training).max(axis=0)\n",
    "\n",
    "# 훈련 데이터에서 최솟값을 빼고 범위로 나누면\n",
    "# 각 특성에 대한 최솟값 = 0, 최댓값 = 1\n",
    "X_train_scaled = (X_train - min_on_training) / range_on_training\n",
    "\n",
    "# 테스트 세트에도 같은 작업\n",
    "min_on_test = X_test.min(axis=0)\n",
    "range_on_test = (X_test - min_on_test).max(axis=0)\n",
    "X_test_scaled = (X_test - min_on_test) / range_on_test\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(svc.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(svc.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 성능 향상을 위해 데이터 전처리를 수행했는데 오히려 정확도가 떨어졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 1.000\n",
      "테스트 세트 정확도 : 0.797\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1000)\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(svc.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(svc.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 규제매개변수 c를 크게 하면 제약이 약해져서 과대적합이 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.92\n",
      "테스트 세트 정확도 : 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kym28\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.2f}\".format(lsvc.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.2f}\".format(lsvc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - LinearSVC는 SVC보다 선형 분류 가능한 데이터에 적합한 모델이다.\n",
    "#### - 테스트 세트에서의 차이는 없으나 훈련 세트 정확도는 LinearSVC가 더 높게 나온 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.991\n",
      "테스트 세트 정확도 : 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kym28\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Cancer 데이터 Z-Score 표준화\n",
    "# 훈련 세트 각 특성의 평균을 계산\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "# 훈련 세트 각 특성의 표준 편차 계산\n",
    "std_on_train = X_train.std(axis=0)\n",
    "\n",
    "# 데이터에서 평균을 빼고 표준 편차로 나누면\n",
    "# 평균 0, 표준 편차 1인 데이터로 변환\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train\n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 1.000\n",
      "테스트 세트 정확도 : 0.972\n"
     ]
    }
   ],
   "source": [
    "# 반복횟수를 증가 (default = 200, SVC accuracy : 0.972)\n",
    "mlp = MLPClassifier(max_iter=1000, random_state=0)\n",
    "\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.988\n",
      "테스트 세트 정확도 : 0.972\n"
     ]
    }
   ],
   "source": [
    "# alpha 증가\n",
    "mlp = MLPClassifier(max_iter=1000, alpha=1, random_state=0)\n",
    "\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - alpha를 증가시켜서 규제를 강화해도 반복 횟수 증가로 인해 성능이 향상됐기 때문에 큰 변화가 없다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
